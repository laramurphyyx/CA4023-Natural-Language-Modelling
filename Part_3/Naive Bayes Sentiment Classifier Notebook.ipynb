{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Baye's rule (for document d and class c) is:\n",
    "$$\n",
    "    P(c|d) = \\frac{P(d|c) P(c)}{P(d)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The denominator can be dropped, and allows the rule to become: \n",
    "$\n",
    "    P(c|d) = P(d|c)P(c)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C_{MAP}$ (Maximum A Posteriori) is the most likely class, and can be calculated using:\n",
    "\n",
    "$$\n",
    "    C_{MAP} = argmax_{c}[ P(d|c)P(c) ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, each document is a review. \n",
    "The features of this document will be the words contained in the review. A review with n words will have the following probability:\n",
    "$$\n",
    "    P(c|d) = P(x_{1}, x_{2}, ..., x_{n}|c)P(c)\n",
    "$$\n",
    "\n",
    "Since independence is assumed with Naive Bayes, this formula can be simplified to:\n",
    "\n",
    "$$\n",
    "    P(c|d) = P(x_{1}|c)P(x_{2}|c)...P(x_{n}|c)P(c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some reviews may have hundreds of words, and the result of this multiplication may get very small, so we will add the log probabilities instead, as it does not affect the ranking of the classes. We will use the following formula:\n",
    "\n",
    "\n",
    "$$\n",
    "    argmax_{c}[log(P(c_{j})) + \\sum_i log(P(x_{i}|c_{j}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notations and Formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(c_{j}) = \\frac{\\text{number of documents in class }c_{j}}{\\text{total number of documents in all classes}} = \\text{What proportion of all classes is }c_{j}?\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    P(w_{j}|c_{i}) = \\frac{\\text{number of times word }w_{j}\\text{ appears in class }c_{i}}{\\text{total number of words that appear in class }c_{i}} = \\text{What proportion of all words is }w_{j}?\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps Taken to Improve Performance\n",
    "\n",
    "* <b>Smoothing the data</b>: Although we have a large dataset, it is possible that certain features (words) will not appear in the test dataset. If words do not appear in the test dataset for either class, they are ignored. Otherwise, we will use the Laplace smoothing algorithm, which prevents 0-probabilities by adding 1:\n",
    "\n",
    "$$ \n",
    "    P(w_{i}|c) = \\frac{(\\text{number of times word }w_{j}\\text{ appears in class }c_{i}) + 1}{(\\text{total number of words that appear in class }c_{i}) + 1} \n",
    "$$\n",
    "\n",
    "* <b>Ignoring punctuation</b>: The reviews have been formatted such that each feature (word/punctuation) have been seperated. This allows for punctuation to be ignored easily in a simple 'if' clause. \n",
    "\n",
    "I chose not to remove the use of stop words (such as 'the' or 'a') as this has shown to have little/no benefits to the performance of a Naive Bayes Classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Concatenating Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_directory = '../Part_3/review_polarity/txt_sentoken/pos'\n",
    "positive_reviews_list = []\n",
    "\n",
    "for filename in os.listdir(pos_directory):\n",
    "    file_path = pos_directory + \"/\" + filename\n",
    "    file = open(file_path, \"r\")\n",
    "    review = []\n",
    "    for line in file.readlines():\n",
    "        review.append(line.rstrip())\n",
    "    positive_reviews_list.append(\" \".join(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_directory = '../Part_3/review_polarity/txt_sentoken/neg'\n",
    "negative_reviews_list = []\n",
    "\n",
    "for filename in os.listdir(neg_directory):\n",
    "    file_path = neg_directory + \"/\" + filename\n",
    "    file = open(file_path, \"r\")\n",
    "    review = []\n",
    "    for line in file.readlines():\n",
    "        review.append(line.rstrip())\n",
    "    negative_reviews_list.append(\" \".join(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning Important Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning the test and training data\n",
    "negative_training_data = negative_reviews_list[:900]\n",
    "positive_training_data = positive_reviews_list[:900]\n",
    "negative_test_data = negative_reviews_list[900:]\n",
    "positive_test_data = positive_reviews_list[900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_dictionary(list_of_reviews):\n",
    "    review_dictionary = {}\n",
    "    for review in list_of_reviews:\n",
    "        words = review.split()\n",
    "        for word in words:\n",
    "            if word in review_dictionary:\n",
    "                review_dictionary[word] += 1\n",
    "            else:\n",
    "                review_dictionary[word] = 1\n",
    "    return review_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_for_class(review, training_data):\n",
    "    punctuation = ['.', ',', ':', '\"', '&', '?', '-', '(', ')', \"'\", '/']\n",
    "    class_result = math.log(0.5)\n",
    "    dictionary = create_frequency_dictionary(training_data)\n",
    "    for word in review.split():\n",
    "        if word in punctuation:\n",
    "            continue\n",
    "        elif word not in dictionary:\n",
    "            class_result += math.log(1 / (sum(dictionary.values()) + 1))\n",
    "        else:\n",
    "            class_result += math.log((dictionary[word] + 1) / (sum(dictionary.values()) + 1))\n",
    "    return class_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "total = 0\n",
    "\n",
    "for review in positive_test_data:\n",
    "    positive_result = result_for_class(review, positive_training_data)\n",
    "    negative_result = result_for_class(review, negative_training_data)\n",
    "    if positive_result > negative_result:\n",
    "        accuracy += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does not have amazing performance on the positive reviews as it only classifies 78% of reviews correctly, let's see if it performs better in the negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "total = 0\n",
    "\n",
    "for review in negative_test_data:\n",
    "    positive_result = result_for_class(review, positive_probability, positive_training_data)\n",
    "    negative_result = result_for_class(review, negative_probability, negative_training_data)\n",
    "    if positive_result < negative_result:\n",
    "        accuracy += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to have a better performance in identifying negative reviews, with an accuracy of 89%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following confusion matrix outlines the performance of the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|                | Predicted Positives | Predicted Negatives |\n",
    "| -------------- | ------------------- | ------------------- |\n",
    "|Actual Positives|         78%         |         11%         |\n",
    "|Actual Negatives|         22%         |         89%         |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
