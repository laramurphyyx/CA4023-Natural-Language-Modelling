{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Baye's rule (for document d and class c) is:\n",
    "$$\n",
    "    P(c|d) = \\frac{P(d|c) P(c)}{P(d)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The denominator can be dropped, and allows the rule to become: \n",
    "$\n",
    "    P(c|d) = P(d|c)P(c)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C_{MAP}$ (Maximum A Posteriori) is the most likely class, and can be calculated using:\n",
    "\n",
    "$$\n",
    "    C_{MAP} = argmax_{c}[ P(d|c)P(c) ]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, each document is a review. \n",
    "The features of this document will be the words contained in the review. A review with n words will have the following probability:\n",
    "$$\n",
    "    P(c|d) = P(x_{1}, x_{2}, ..., x_{n}|c)P(c)\n",
    "$$\n",
    "\n",
    "Since independence is assumed with Naive Bayes, this formula can be simplified to:\n",
    "\n",
    "$$\n",
    "    P(c|d) = P(x_{1}|c)P(x_{2}|c)...P(x_{n}|c)P(c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some reviews may have hundreds of words, and the result of this multiplication may get very small, so we will add the log probabilities instead, as it does not affect the ranking of the classes. We will use the following formula:\n",
    "\n",
    "\n",
    "$$\n",
    "    argmax_{c}[log(P(c_{j})) + \\sum_i log(P(x_{i}|c_{j}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notations and Formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(c_{j}) = \\frac{\\text{number of documents in class }c_{j}}{\\text{total number of documents in all classes}} = \\text{What proportion of all classes is }c_{j}?\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    P(w_{j}|c_{i}) = \\frac{\\text{number of times word }w_{j}\\text{ appears in class }c_{i}}{\\text{total number of words that appear in class }c_{i}} = \\text{What proportion of all words is }w_{j}?\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps Taken to Improve Performance\n",
    "\n",
    "* <b>Smoothing the data</b>: Although we have a large dataset, it is possible that certain features (words) will not appear in the test dataset. If words do not appear in the test dataset for either class, they are ignored. Otherwise, we will use the Laplace smoothing algorithm, which prevents 0-probabilities by adding 1:\n",
    "\n",
    "$$ \n",
    "    P(w_{i}|c) = \\frac{(\\text{number of times word }w_{j}\\text{ appears in class }c_{i}) + 1}{(\\text{total number of words that appear in class }c_{i}) + 1} \n",
    "$$\n",
    "\n",
    "* <b>Ignoring punctuation</b>: The reviews have been formatted such that each feature (word/punctuation) have been seperated. This allows for punctuation to be ignored easily in a simple 'if' clause. \n",
    "\n",
    "I chose not to remove the use of stop words (such as 'the' or 'a') as this has shown to have little/no benefits to the performance of a Naive Bayes Classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Concatenating Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_directory = '../Part_3/review_polarity/txt_sentoken/pos'\n",
    "positive_reviews_list = []\n",
    "\n",
    "for filename in os.listdir(pos_directory):\n",
    "    file_path = pos_directory + \"/\" + filename\n",
    "    file = open(file_path, \"r\")\n",
    "    review = []\n",
    "    for line in file.readlines():\n",
    "        review.append(line.rstrip())\n",
    "    positive_reviews_list.append(\" \".join(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_directory = '../Part_3/review_polarity/txt_sentoken/neg'\n",
    "negative_reviews_list = []\n",
    "\n",
    "for filename in os.listdir(neg_directory):\n",
    "    file_path = neg_directory + \"/\" + filename\n",
    "    file = open(file_path, \"r\")\n",
    "    review = []\n",
    "    for line in file.readlines():\n",
    "        review.append(line.rstrip())\n",
    "    negative_reviews_list.append(\" \".join(review))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning Important Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assigning the test and training data\n",
    "negative_training_data = negative_reviews_list[:900]\n",
    "positive_training_data = positive_reviews_list[:900]\n",
    "negative_test_data = negative_reviews_list[900:]\n",
    "positive_test_data = positive_reviews_list[900:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model Functions & Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_dictionary(list_of_reviews):\n",
    "    review_dictionary = {}\n",
    "    for review in list_of_reviews:\n",
    "        words = review.split()\n",
    "        for word in words:\n",
    "            if word in review_dictionary:\n",
    "                review_dictionary[word] += 1\n",
    "            else:\n",
    "                review_dictionary[word] = 1\n",
    "    return review_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_for_class(review, training_data):\n",
    "    punctuation = ['.', ',', ':', '\"', '&', '?', '-', '(', ')', \"'\", '/']\n",
    "    class_result = math.log(0.5)\n",
    "    dictionary = create_frequency_dictionary(training_data)\n",
    "    for word in review.split():\n",
    "        if word in punctuation:\n",
    "            continue\n",
    "        elif word not in dictionary:\n",
    "            class_result += math.log(1 / (sum(dictionary.values()) + 1))\n",
    "        else:\n",
    "            class_result += math.log((dictionary[word] + 1) / (sum(dictionary.values()) + 1))\n",
    "    return class_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "total = 0\n",
    "\n",
    "for review in positive_test_data:\n",
    "    positive_result = result_for_class(review, positive_training_data)\n",
    "    negative_result = result_for_class(review, negative_training_data)\n",
    "    if positive_result > negative_result:\n",
    "        accuracy += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy in identifying positive reviews is: 78.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"The model's accuracy in identifying positive reviews is: \" + str(accuracy / total * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model does not have amazing performance on the positive reviews as it only classifies 78% of reviews correctly, let's see if it performs better in the negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "total = 0\n",
    "\n",
    "for review in negative_test_data:\n",
    "    positive_result = result_for_class(review, positive_training_data)\n",
    "    negative_result = result_for_class(review, negative_training_data)\n",
    "    if positive_result < negative_result:\n",
    "        accuracy += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's accuracy in identifying negative reviews is: 89.0%\n"
     ]
    }
   ],
   "source": [
    "print(\"The model's accuracy in identifying negative reviews is: \" + str(accuracy / total * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model seems to have a better performance in identifying negative reviews, with an accuracy of 89%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following confusion matrix outlines the performance of the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|                | Predicted Positives | Predicted Negatives |\n",
    "| -------------- | ------------------- | ------------------- |\n",
    "|Actual Positives|         78%         |         11%         |\n",
    "|Actual Negatives|         22%         |         89%         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Errors in Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews_misclassified = []\n",
    "\n",
    "for review in positive_test_data:\n",
    "    positive_result = result_for_class(review, positive_training_data)\n",
    "    negative_result = result_for_class(review, negative_training_data)\n",
    "    if positive_result < negative_result:\n",
    "        positive_reviews_misclassified.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews_misclassified = []\n",
    "\n",
    "for review in negative_test_data:\n",
    "    positive_result = result_for_class(review, positive_training_data)\n",
    "    negative_result = result_for_class(review, negative_training_data)\n",
    "    if positive_result > negative_result:\n",
    "        negative_reviews_misclassified.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews_sample_ids = random.sample(list(np.arange(0,22)), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 10, 12, 3, 21]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_reviews_sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_reviews_sample_ids = random.sample(list(np.arange(0,len(negative_reviews_misclassified))), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 10, 4, 9, 5]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_reviews_sample_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Misclassified Positive Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each sampled review, we will look at the tokens with the highest count in the review, then we will compare the frequency of these words within the positive review dictionary and the negative review dictionary.\n",
    "\n",
    "Let's have an initial look at the 12th misclassified review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_dict1 = create_frequency_dictionary([positive_reviews_misclassified[12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(review_dict1.items(), key=lambda x: x[1], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 20 most frequent words in this first review are:\n",
    "\n",
    "1. ('.', 46) -> punctuation\n",
    "\n",
    "2. ('the', 36) -> determiner\n",
    " \n",
    "3. (',', 23) -> punctuation\n",
    " \n",
    "4. ('to', 19) -> particle\n",
    " \n",
    "5. ('and', 16) -> conjunction\n",
    " \n",
    "6. ('in', 14) -> preposition\n",
    " \n",
    "7. ('a', 13) -> determiner\n",
    " \n",
    "8. ('of', 11) -> preposition\n",
    " \n",
    "9. ('\"', 10) -> punctuation\n",
    " \n",
    "10. ('(', 9) -> punctuation\n",
    " \n",
    "11. (')', 9) -> punctuation\n",
    " \n",
    "12. ('that', 9) -> determiner/conjunction\n",
    " \n",
    "13. ('is', 9) -> verb\n",
    " \n",
    "14. ('film', 8) -> noun\n",
    " \n",
    "15. ('as', 8) -> conjunction/preposition\n",
    " \n",
    "16. ('car', 7) -> noun\n",
    " \n",
    "17. ('his', 7) -> pronoun\n",
    " \n",
    "18. ('just', 7) -> adjective/adverb\n",
    " \n",
    "19. ('memphis', 6) -> noun\n",
    " \n",
    "20. ('have', 6) -> verb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is expected, as punctuation and determiners/particles/prepositions etc. are more common than nouns or adjectives. \n",
    "\n",
    "We will have a look at a few of the most common nouns, verbs, adjectives and adverbs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ('is', 9)\n",
    "* ('film', 8)\n",
    "* ('car', 7)\n",
    "* ('just', 7)\n",
    "* ('memphis', 6)\n",
    "* ('have', 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dictionary = create_frequency_dictionary(positive_training_data)\n",
    "negative_dictionary = create_frequency_dictionary(negative_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'is' appears in the positive dictionary 12549 times\n",
      "'is' appears in the negative dictionary 9952 times\n"
     ]
    }
   ],
   "source": [
    "print(\"'is' appears in the positive dictionary \" + str(positive_dictionary['is']) + \" times\")\n",
    "print(\"'is' appears in the negative dictionary \" + str(negative_dictionary['is']) + \" times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'film' appears in the positive dictionary 4376 times\n",
      "'film' appears in the negative dictionary 3598 times\n"
     ]
    }
   ],
   "source": [
    "print(\"'film' appears in the positive dictionary \" + str(positive_dictionary['film']) + \" times\")\n",
    "print(\"'film' appears in the negative dictionary \" + str(negative_dictionary['film']) + \" times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'car' appears in the positive dictionary 112 times\n",
      "'car' appears in the negative dictionary 165 times\n"
     ]
    }
   ],
   "source": [
    "print(\"'car' appears in the positive dictionary \" + str(positive_dictionary['car']) + \" times\")\n",
    "print(\"'car' appears in the negative dictionary \" + str(negative_dictionary['car']) + \" times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'just' appears in the positive dictionary 1197 times\n",
      "'just' appears in the negative dictionary 1390 times\n"
     ]
    }
   ],
   "source": [
    "print(\"'just' appears in the positive dictionary \" + str(positive_dictionary['just']) + \" times\")\n",
    "print(\"'just' appears in the negative dictionary \" + str(negative_dictionary['just']) + \" times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'memphis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-e11843967f21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'memphis' appears in the positive dictionary \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'memphis'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" times\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'memphis' appears in the negative dictionary \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_dictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'memphis'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" times\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'memphis'"
     ]
    }
   ],
   "source": [
    "print(\"'memphis' appears in the positive dictionary \" + str(positive_dictionary['memphis']) + \" times\")\n",
    "print(\"'memphis' appears in the negative dictionary \" + str(negative_dictionary['memphis']) + \" times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'have' appears in the positive dictionary 1992 times\n",
      "'have' appears in the negative dictionary 2408 times\n"
     ]
    }
   ],
   "source": [
    "print(\"'have' appears in the positive dictionary \" + str(positive_dictionary['have']) + \" times\")\n",
    "print(\"'have' appears in the negative dictionary \" + str(negative_dictionary['have']) + \" times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to find a reasonable explanation for the misclassification of the review based on the most common words.\n",
    "\n",
    "Another possible method to understand this error is to identify the words that have a much higher ratio of appearing in the negative reviews vs. the positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ratio_positive_review(word, positive_dict, negative_dict):\n",
    "    \n",
    "    # This method finds the ratio of the word count in both the negative and positive dictionaries\n",
    "    # A result less than 1 means that the word appears more in the positive dictionary\n",
    "    # A result more than 1 means that the word appears more in the negative dictionary\n",
    "    \n",
    "    if word not in negative_dict:\n",
    "        return 0 # because the word appears more in the positive dictionary (1-1)\n",
    "    elif word not in positive_dict:\n",
    "        return 2 # because the word appears more in the negative dictionary (1+1)\n",
    "    \n",
    "    return negative_dict[word] / positive_dict[word]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5614035087719298"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_ratio_positive_review('happy', positive_dictionary, negative_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result of ~56% means that the word 'happy' appears in the negative dictionary 56% as much as it appears in the positive dictionary, meaning it appears much more in the positive dictionary than the negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in positive_reviews_misclassified[12].split():\n",
    "    score_dict[word] = find_ratio_positive_review(word, positive_dictionary, negative_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bruckheimer', 18.0),\n",
       " ('memphis', 17.0),\n",
       " ('jolie', 15.0),\n",
       " ('angelina', 7.0),\n",
       " ('shiny', 6.0),\n",
       " ('hottest', 4.0),\n",
       " ('mindset', 3.5),\n",
       " ('jumping', 3.142857142857143),\n",
       " ('dominic', 3.0),\n",
       " ('improvise', 3.0),\n",
       " ('cage', 2.9166666666666665),\n",
       " ('bad', 2.833846153846154),\n",
       " ('remake', 2.5454545454545454),\n",
       " ('seconds', 2.4210526315789473),\n",
       " ('none', 2.3278688524590163),\n",
       " ('kalifornia', 2.0),\n",
       " ('nicolas', 2.0),\n",
       " ('assorted', 2.0),\n",
       " ('lindo', 2.0),\n",
       " (\"lindo's\", 2),\n",
       " ('chases', 2.0),\n",
       " ('ramp', 2),\n",
       " ('filmmakers', 1.9482758620689655),\n",
       " ('armageddon', 1.9473684210526316),\n",
       " ('unfortunately', 1.8956521739130434),\n",
       " ('christopher', 1.8571428571428572),\n",
       " ('cars', 1.8421052631578947),\n",
       " ('loud', 1.78125),\n",
       " ('halfway', 1.7777777777777777),\n",
       " ('monkey', 1.736842105263158),\n",
       " ('speed', 1.7037037037037037),\n",
       " ('partner', 1.631578947368421),\n",
       " ('postman', 1.5714285714285714),\n",
       " ('oh', 1.5277777777777777),\n",
       " ('plot', 1.5265225933202358),\n",
       " ('sixty', 1.5),\n",
       " (\"anyone's\", 1.5),\n",
       " ('car', 1.4732142857142858),\n",
       " ('add', 1.46875),\n",
       " ('credits', 1.463768115942029),\n",
       " (\"there's\", 1.4254742547425474),\n",
       " ('should', 1.4143302180685358),\n",
       " ('wondering', 1.4),\n",
       " ('?', 1.365598885793872),\n",
       " (\"i'm\", 1.3559322033898304),\n",
       " ('no', 1.3530054644808742),\n",
       " ('dialogue', 1.3473684210526315),\n",
       " ('elude', 1.3333333333333333),\n",
       " ('either', 1.3221476510067114),\n",
       " ('name', 1.3129251700680271),\n",
       " ('action', 1.3113207547169812),\n",
       " ('jerry', 1.297872340425532),\n",
       " ('movie', 1.2906755470980018),\n",
       " ('edited', 1.2857142857142858),\n",
       " ('fan', 1.2833333333333334),\n",
       " ('chase', 1.280701754385965),\n",
       " ('thought', 1.2781456953642385),\n",
       " ('kill', 1.2678571428571428),\n",
       " ('if', 1.2671480144404332),\n",
       " ('given', 1.2663316582914572),\n",
       " ('gone', 1.2638888888888888),\n",
       " ('gang', 1.2564102564102564),\n",
       " ('could', 1.2527075812274369),\n",
       " (\"i'd\", 1.2388059701492538),\n",
       " (\"don't\", 1.2344398340248963),\n",
       " (\"aren't\", 1.2222222222222223),\n",
       " ('hot', 1.2142857142857142),\n",
       " ('have', 1.2088353413654618),\n",
       " ('looking', 1.2011834319526626),\n",
       " ('trying', 1.2008733624454149),\n",
       " ('delroy', 1.2),\n",
       " ('department', 1.1923076923076923),\n",
       " ('do', 1.1889460154241644),\n",
       " ('i', 1.188519243313764),\n",
       " ('only', 1.1879327398615231),\n",
       " ('director', 1.1870669745958429),\n",
       " ('suspense', 1.1794871794871795),\n",
       " ('performers', 1.173913043478261),\n",
       " ('get', 1.1727616645649432),\n",
       " ('huge', 1.1714285714285715),\n",
       " ('even', 1.167785234899329),\n",
       " ('lend', 1.1666666666666667),\n",
       " ('just', 1.1612364243943192),\n",
       " ('big', 1.1598984771573604),\n",
       " ('know', 1.158102766798419),\n",
       " ('so', 1.1529255319148937),\n",
       " (\"she's\", 1.1515151515151516),\n",
       " ('made', 1.1485849056603774),\n",
       " ('think', 1.1472222222222221),\n",
       " ('stunt', 1.1428571428571428),\n",
       " ('provoking', 1.1428571428571428),\n",
       " ('here', 1.141304347826087),\n",
       " ('producer', 1.1395348837209303),\n",
       " ('going', 1.1366120218579234),\n",
       " ('had', 1.1365030674846626),\n",
       " ('retired', 1.125),\n",
       " ('mentor', 1.125),\n",
       " ('or', 1.1237585943468296),\n",
       " ('meat', 1.1176470588235294),\n",
       " ('eye', 1.1129032258064515),\n",
       " (\"doesn't\", 1.111531190926276),\n",
       " ('rock', 1.1095890410958904),\n",
       " ('there', 1.1090128755364808),\n",
       " ('interesting', 1.101123595505618),\n",
       " ('summer', 1.0952380952380953),\n",
       " ('\"', 1.091342335186656),\n",
       " ('flick', 1.0897435897435896),\n",
       " ('been', 1.0835214446952597),\n",
       " ('wish', 1.0833333333333333),\n",
       " ('around', 1.0805194805194804),\n",
       " ('audience', 1.077127659574468),\n",
       " ('opportunity', 1.0740740740740742),\n",
       " (\"who's\", 1.0708661417322836),\n",
       " ('having', 1.0702479338842976),\n",
       " ('how', 1.0651515151515152),\n",
       " ('make', 1.0640465793304221),\n",
       " ('this', 1.0638708122439142),\n",
       " ('gets', 1.0638297872340425),\n",
       " ('some', 1.0613496932515338),\n",
       " ('thief', 1.0588235294117647),\n",
       " ('hard', 1.0588235294117647),\n",
       " ('would', 1.0569196428571428),\n",
       " ('about', 1.0516002612671456),\n",
       " ('be', 1.050243719535058),\n",
       " ('title', 1.047244094488189),\n",
       " ('end', 1.0455531453362257),\n",
       " ('rival', 1.0357142857142858),\n",
       " ('steal', 1.032258064516129),\n",
       " ('out', 1.027062706270627),\n",
       " ('you', 1.026275896917635),\n",
       " ('line', 1.0172413793103448),\n",
       " ('up', 1.0130434782608695),\n",
       " ('all', 1.0047244094488188),\n",
       " ('sena', 1.0),\n",
       " ('1974', 1.0),\n",
       " ('absolutely', 1.0),\n",
       " ('overlord', 1.0),\n",
       " (\"memphis'\", 1.0),\n",
       " ('ribisi', 1.0),\n",
       " ('opening', 1.0),\n",
       " ('moby', 1.0),\n",
       " ('patton', 1.0),\n",
       " ('someday', 1.0),\n",
       " ('pursuit', 1.0),\n",
       " ('timothy', 1.0),\n",
       " ('was', 0.987410071942446),\n",
       " ('on', 0.9849877450980392),\n",
       " ('much', 0.9836779107725789),\n",
       " ('before', 0.9821029082774049),\n",
       " ('kind', 0.9761904761904762),\n",
       " (\"it's\", 0.9740566037735849),\n",
       " ('go', 0.970954356846473),\n",
       " ('crew', 0.96875),\n",
       " ('sure', 0.9647577092511013),\n",
       " ('put', 0.9629629629629629),\n",
       " ('little', 0.9606986899563319),\n",
       " ('them', 0.9578947368421052),\n",
       " ('members', 0.9565217391304348),\n",
       " ('.', 0.9551108170691366),\n",
       " (')', 0.955083179297597),\n",
       " ('days', 0.9523809523809523),\n",
       " ('time', 0.9474689589302769),\n",
       " ('that', 0.9462257368799425),\n",
       " ('things', 0.9461538461538461),\n",
       " ('plays', 0.9457142857142857),\n",
       " ('(', 0.9444547650009288),\n",
       " ('can', 0.9415774099318404),\n",
       " ('what', 0.9410929737402413),\n",
       " ('good', 0.9410112359550562),\n",
       " ('close', 0.9369369369369369),\n",
       " ('to', 0.9354247300875942),\n",
       " ('because', 0.9334186939820742),\n",
       " ('it', 0.9322625698324022),\n",
       " ('business', 0.9310344827586207),\n",
       " ('but', 0.9298201798201798),\n",
       " ('package', 0.9285714285714286),\n",
       " ('not', 0.9183912534166341),\n",
       " ('scene', 0.9165378670788253),\n",
       " ('real', 0.9164619164619164),\n",
       " ('characters', 0.9125295508274232),\n",
       " ('cast', 0.9119318181818182),\n",
       " ('conclusion', 0.9090909090909091),\n",
       " ('bring', 0.908256880733945),\n",
       " ('comes', 0.9067055393586005),\n",
       " ('along', 0.904),\n",
       " ('essentially', 0.9032258064516129),\n",
       " ('exactly', 0.900709219858156),\n",
       " ('finale', 0.9),\n",
       " ('old', 0.896551724137931),\n",
       " ('three', 0.8959731543624161),\n",
       " ('for', 0.8917767362590541),\n",
       " ('tell', 0.8909090909090909),\n",
       " ('one', 0.8894414690130069),\n",
       " ('an', 0.889218228973694),\n",
       " ('determined', 0.8857142857142857),\n",
       " ('a', 0.8844115698829764),\n",
       " ('tune', 0.8823529411764706),\n",
       " ('turns', 0.8823529411764706),\n",
       " ('brother', 0.8785046728971962),\n",
       " ('through', 0.8769497400346621),\n",
       " ('kid', 0.8735632183908046),\n",
       " ('are', 0.8720336437368579),\n",
       " ('these', 0.8710191082802548),\n",
       " ('those', 0.8704453441295547),\n",
       " ('we', 0.8679927667269439),\n",
       " ('50', 0.8666666666666667),\n",
       " ('in', 0.8591954022988506),\n",
       " ('evil', 0.8585858585858586),\n",
       " ('former', 0.8571428571428571),\n",
       " ('candy', 0.8571428571428571),\n",
       " ('successfully', 0.8571428571428571),\n",
       " ('bus', 0.8571428571428571),\n",
       " ('back', 0.8531187122736419),\n",
       " ('sequence', 0.847457627118644),\n",
       " ('the', 0.8468634187248086),\n",
       " ('roles', 0.8455882352941176),\n",
       " ('ever', 0.8435754189944135),\n",
       " ('from', 0.8434891485809682),\n",
       " ('has', 0.8411739318083729),\n",
       " ('us', 0.8384030418250951),\n",
       " ('leaves', 0.8352941176470589),\n",
       " ('with', 0.8327003418154196),\n",
       " ('way', 0.8319226118500604),\n",
       " (',', 0.8303705065252213),\n",
       " ('same', 0.8301435406698564),\n",
       " ('who', 0.8301318267419963),\n",
       " ('of', 0.8300445193117555),\n",
       " ('film', 0.8222120658135283),\n",
       " ('though', 0.8207343412526998),\n",
       " ('see', 0.82063305978898),\n",
       " ('other', 0.8202959830866807),\n",
       " ('does', 0.8146718146718147),\n",
       " ('break', 0.810126582278481),\n",
       " ('fun', 0.8042704626334519),\n",
       " (\"i've\", 0.8031088082901554),\n",
       " ('feels', 0.8018018018018018),\n",
       " ('trail', 0.8),\n",
       " ('blew', 0.8),\n",
       " ('[pg-13]', 0.8),\n",
       " ('its', 0.799469964664311),\n",
       " ('meet', 0.7982456140350878),\n",
       " ('finally', 0.7976878612716763),\n",
       " ('making', 0.7935943060498221),\n",
       " ('is', 0.7930512391425611),\n",
       " ('him', 0.7885628291948834),\n",
       " ('and', 0.7883908890521675),\n",
       " ('pulled', 0.7878787878787878),\n",
       " ('shot', 0.7839506172839507),\n",
       " ('by', 0.7780596068484464),\n",
       " ('delivery', 0.7777777777777778),\n",
       " ('role', 0.7777777777777778),\n",
       " ('during', 0.7767584097859327),\n",
       " ('four', 0.7674418604651163),\n",
       " ('as', 0.7628205128205128),\n",
       " ('right', 0.7611940298507462),\n",
       " ('while', 0.7598978288633461),\n",
       " ('roll', 0.7575757575757576),\n",
       " ('however', 0.7550200803212851),\n",
       " ('done', 0.7532467532467533),\n",
       " ('meaty', 0.75),\n",
       " ('he', 0.7481405488586818),\n",
       " ('unfortunate', 0.7419354838709677),\n",
       " ('together', 0.7389705882352942),\n",
       " ('adding', 0.7368421052631579),\n",
       " ('story', 0.7358318098720292),\n",
       " ('provide', 0.7352941176470589),\n",
       " ('objects', 0.7333333333333333),\n",
       " ('stands', 0.7333333333333333),\n",
       " ('mind', 0.7323943661971831),\n",
       " ('discovers', 0.7321428571428571),\n",
       " ('picture', 0.7319587628865979),\n",
       " ('well', 0.731535756154748),\n",
       " ('wrapped', 0.7222222222222222),\n",
       " ('will', 0.7210113339145597),\n",
       " ('robert', 0.72),\n",
       " ('his', 0.7166234284573937),\n",
       " ('giovanni', 0.7142857142857143),\n",
       " ('ways', 0.7142857142857143),\n",
       " ('entertaining', 0.7080745341614907),\n",
       " ('thereby', 0.7),\n",
       " ('sets', 0.6984126984126984),\n",
       " ('doubt', 0.6881720430107527),\n",
       " ('love', 0.6781411359724613),\n",
       " ('detective', 0.6764705882352942),\n",
       " ('tidy', 0.6666666666666666),\n",
       " ('challenging', 0.6666666666666666),\n",
       " ('seen', 0.6652806652806653),\n",
       " ('easily', 0.6576576576576577),\n",
       " ('entertainment', 0.6576576576576577),\n",
       " ('using', 0.6574074074074074),\n",
       " ('carry', 0.6567164179104478),\n",
       " ('supporting', 0.6510067114093959),\n",
       " ('most', 0.6477181745396317),\n",
       " ('mainly', 0.6470588235294118),\n",
       " ('demise', 0.6428571428571429),\n",
       " ('also', 0.6389925373134329),\n",
       " ('minor', 0.6388888888888888),\n",
       " ('despite', 0.6387434554973822),\n",
       " ('very', 0.6345029239766082),\n",
       " ('specifically', 0.6190476190476191),\n",
       " ('follows', 0.6170212765957447),\n",
       " ('important', 0.6146788990825688),\n",
       " ('job', 0.6091205211726385),\n",
       " ('told', 0.6083333333333333),\n",
       " ('slick', 0.6),\n",
       " ('ride', 0.589041095890411),\n",
       " ('stolen', 0.5588235294117647),\n",
       " ('highly', 0.5571428571428572),\n",
       " ('duvall', 0.5517241379310345),\n",
       " ('detectives', 0.5333333333333333),\n",
       " ('simple', 0.5279503105590062),\n",
       " ('underrated', 0.5263157894736842),\n",
       " ('definitely', 0.5247524752475248),\n",
       " ('performances', 0.5238095238095238),\n",
       " (\"rockin'\", 0.5),\n",
       " ('exasperated', 0.5),\n",
       " ('sometimes', 0.4939759036144578),\n",
       " ('nicely', 0.4745762711864407),\n",
       " ('pure', 0.47368421052631576),\n",
       " ('class', 0.4523809523809524),\n",
       " ('anymore', 0.4444444444444444),\n",
       " ('photographs', 0.42857142857142855),\n",
       " ('eccleston', 0.4),\n",
       " ('mannerisms', 0.36363636363636365),\n",
       " ('disappoint', 0.3333333333333333),\n",
       " ('gripe', 0.3333333333333333),\n",
       " ('perfectly', 0.3017241379310345),\n",
       " ('shorty', 0.2727272727272727),\n",
       " ('olyphant', 0.25),\n",
       " ('particulars', 0.25),\n",
       " ('shines', 0.23809523809523808),\n",
       " ('grease', 0.17391304347826086),\n",
       " ('ordered', 0.16666666666666666),\n",
       " ('complaints', 0.15384615384615385)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(score_dict.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 334 unique words in the review, it appears there are 133 words that scored above 1, 12 words that are scored exactly 1 and 189 words that scored less than 1. \n",
    "\n",
    "This means that there are more words that are associated with positive reviews than negative reviews. This does not explain why this review is classified as a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
